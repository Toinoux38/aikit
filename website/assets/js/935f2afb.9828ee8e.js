"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"sidebar":[{"type":"link","label":"Introduction","href":"/aikit/","docId":"intro","unlisted":false},{"type":"link","label":"Quick Start","href":"/aikit/quick-start","docId":"quick-start","unlisted":false},{"type":"link","label":"Pre-made Models","href":"/aikit/premade-models","docId":"premade-models","unlisted":false},{"type":"link","label":"Demos","href":"/aikit/demo","docId":"demo","unlisted":false},{"type":"link","label":"Creating Model Images","href":"/aikit/create-images","docId":"create-images","unlisted":false},{"type":"link","label":"API Specifications","href":"/aikit/specs","docId":"specs","unlisted":false},{"type":"link","label":"GPU Acceleration","href":"/aikit/gpu","docId":"gpu","unlisted":false},{"type":"link","label":"Kubernetes Deployment","href":"/aikit/kubernetes","docId":"kubernetes","unlisted":false},{"type":"link","label":"Image Verification","href":"/aikit/cosign","docId":"cosign","unlisted":false}]},"docs":{"cosign":{"id":"cosign","title":"Image Verification","description":"AIKit and pre-made models are keyless signed with OIDC in GitHub Actions with cosign. You can verify the images with the following commands:","sidebar":"sidebar"},"create-images":{"id":"create-images","title":"Creating Model Images","description":"This section shows how to create a custom image with models of your choosing. If you want to use one of the pre-made models, skip to running models.","sidebar":"sidebar"},"demo":{"id":"demo","title":"Demos","description":"Building an image with a Llama 2 model","sidebar":"sidebar"},"gpu":{"id":"gpu","title":"GPU Acceleration","description":"At this time, only NVIDIA GPU acceleration is supported. Please open an issue if you\'d like to see support for other GPU vendors.","sidebar":"sidebar"},"intro":{"id":"intro","title":"Introduction","description":"AIKit is a quick, easy, and local or cloud-agnostic way to get started to host and deploy large language models (LLMs) for inference. No GPU, internet access or additional tools are needed to get started except for Docker!","sidebar":"sidebar"},"kubernetes":{"id":"kubernetes","title":"Kubernetes Deployment","description":"It is easy to get started to deploy your models to Kubernetes!","sidebar":"sidebar"},"premade-models":{"id":"premade-models","title":"Pre-made Models","description":"AIKit comes with pre-made models that you can use out-of-the-box!","sidebar":"sidebar"},"quick-start":{"id":"quick-start","title":"Quick Start","description":"You can get started with AIKit quickly on your local machine without a GPU!","sidebar":"sidebar"},"specs":{"id":"specs","title":"API Specifications","description":"v1alpha1","sidebar":"sidebar"}}}')}}]);