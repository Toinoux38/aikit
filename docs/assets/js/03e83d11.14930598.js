"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[56],{5145:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>r,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>c});var a=n(5893),s=n(1151);const o={title:"API Specifications"},i=void 0,l={id:"specs",title:"API Specifications",description:"v1alpha1",source:"@site/docs/specs.md",sourceDirName:".",slug:"/specs",permalink:"/aikit/specs",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/specs.md",tags:[],version:"current",frontMatter:{title:"API Specifications"},sidebar:"sidebar",previous:{title:"Creating Model Images",permalink:"/aikit/create-images"},next:{title:"GPU Acceleration",permalink:"/aikit/gpu"}},r={},c=[{value:"v1alpha1",id:"v1alpha1",level:2}];function p(e){const t={code:"code",h2:"h2",p:"p",pre:"pre",...(0,s.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.h2,{id:"v1alpha1",children:"v1alpha1"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-yaml",children:'apiVersion: # required. only v1alpha1 is supported at the moment\ndebug: # optional. if set to true, debug logs will be printed\nruntime: # optional. defaults to avx. can be "avx", "avx2", "avx512", "cuda"\nbackends: # optional. list of additional backends. can be "stablediffusion", "exllama" or "exllama2"\nmodels: # required. list of models to build\n  - name: # required. name of the model\n    source: # required. source of the model. must be a url\n    sha256: # optional. sha256 hash of the model file\n    promptTemplates: # optional. list of prompt templates for a model\n      - name: # required. name of the template\n        template: # required. template string\nconfig: # optional. list of config files\n'})}),"\n",(0,a.jsx)(t.p,{children:"Example:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-yaml",children:'#syntax=ghcr.io/sozercan/aikit:latest\napiVersion: v1alpha1\ndebug: true\nruntime: cuda\nbackends:\n  - stablediffusion\nmodels:\n  - name: llama-2-7b-chat\n    source: https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf\n    sha256: "08a5566d61d7cb6b420c3e4387a39e0078e1f2fe5f055f3a03887385304d4bfa"\n    promptTemplates:\n      - name: "llama-2-7b-chat"\n        template: |\n          {{if eq .RoleName \\"assistant\\"}}{{.Content}}{{else}}\n          [INST]\n          {{if .SystemPrompt}}{{.SystemPrompt}}{{else if eq .RoleName \\"system\\"}}<<SYS>>{{.Content}}<</SYS>>\n\n          {{else if .Content}}{{.Content}}{{end}}\n          [/INST]\n          {{end}}\nconfig: |\n  - name: \\"llama-2-7b-chat\\"\n    backend: \\"llama\\"\n    parameters:\n      top_k: 80\n      temperature: 0.2\n      top_p: 0.7\n      model: \\"llama-2-7b-chat.Q4_K_M.gguf\\"\n    context_size: 4096\n    roles:\n      function: \'Function Result:\'\n      assistant_function_call: \'Function Call:\'\n      assistant: \'Assistant:\'\n      user: \'User:\'\n      system: \'System:\'\n    template:\n      chat_message: \\"llama-2-7b-chat\\"\n    system_prompt: \\"You are a helpful assistant, below is a conversation, please respond with the next message and do not ask follow-up questions\\"\n'})})]})}function m(e={}){const{wrapper:t}={...(0,s.a)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}},1151:(e,t,n)=>{n.d(t,{Z:()=>l,a:()=>i});var a=n(7294);const s={},o=a.createContext(s);function i(e){const t=a.useContext(o);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),a.createElement(o.Provider,{value:t},e.children)}}}]);