#syntax=sozercan/aikit:test
apiVersion: v1alpha1
baseModel: unsloth/llama-2-7b-bnb-4bit
datasets:
  - source: "https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl"
    type: alpaca
    # TODO: figure out type
config:
  unsloth:
    # TODO: add validations
    packing: false
    maxSeqLength: 2048
    loadIn4bit: true
    batchSize: 2
    gradientAccumulationSteps: 4
    warmupSteps: 10
    maxSteps: 60
    learningRate: 0.0002
    loggingSteps: 1
    optimizer: adamw_8bit
    weightDecay: 0.01
    lrSchedulerType: linear
    seed: 42
output:
  quantize: q4_k_m
  name: model
